{
  "title": "AI-Driven Variable Selection for Time Series Forecasting",
  "subtitle": "A Model-Agnostic Meta-Learning Workflow",
  "author": "Andrew Garcia, PhD 2025",
  "controls": {
    "play": "Play",
    "pause": "Pause",
    "reset": "Reset",
    "lang": {
      "en": "EN",
      "es": "ES"
    }
  },

  "what_is_meta_title": "What is Meta-learning?",
  "what_is_meta_text": "Meta-learning means 'learning to learn'. In this system, the experience comes from how forecasting models perform, not just from raw data. After each trial, the system looks at whether a model‚Äôs forecasts improved or worsened, and links that outcome back to descriptors of the chosen variables ‚Äî either their metadata (e.g., institution, start date, classification) or their positional index in the database. By iterating this loop, the system learns rules for better selection over time. Because it learns from the results of other learning processes, it is literally 'learning to learn'.",


  "explain_like_5_title": "Explain Recursive Introspection like I'm 5 üë∂",
  "explain_like_5_text": "Imagine you're picking players for a team. At first you try random players. You see how the team performs üèà. Next time, you remember who played well üß†, and you pick them again. Sometimes you still try someone new üé≤, just in case. Over time, your team keeps getting better because you learn how to pick the best mix. That's what Recursive Introspection does ‚Äî it learns how to pick the best variables to forecast the economy.",


  "orientation_note": "Smartphone detected ‚Äî for the best experience, view in landscape orientation and use the button to minimize the header.",

  "nodes": {
    "database": {
      "label": "Full Time Series DB",
      "description": "Complete historical time series data repository containing all available variables and their temporal patterns."
    },
    "warmup-note": {
      "warmupLabel": "During warmup: always random",
      "activeLabel": "After warmup: epsilon-greedy",
      "warmupDesc": "During the warmup phase, the system always explores randomly to gather initial data.",
      "activeDesc": "After warmup, the system uses epsilon-greedy strategy to balance exploration and exploitation."
    },
    "decision": {
      "label": "Decision point",
      "description": "Decision based on epsilon threshold"
    },
    "introspector": {
      "label": "Introspector G",
      "description": "Neural network that learns to select the most informative variables based on historical performance."
    },
    "random-picker": {
      "label": "Random Variable Picker",
      "description": "Randomly selects variables for exploration to discover potentially useful new combinations."
    },
    "selected-vars": {
      "label": "Selected Variables",
      "description": "The chosen set of variables from either exploitation or exploration strategy."
    },
    "embedder": {
      "label": "Series Embedder (with Metadata)",
      "description": "Transforms selected time series variables into dense vector representations. Obtains: Embeddings of Selected Variables"
    },
    "forecasting": {
      "label": "Forecasting Model",
      "description": "Random Forest regressors, custom Neural Networks, VARs, you name it. Outputs: Forecast Loss."
    },
    "history": {
      "label": "(Embeddings, Loss) ‚Üí History Log",
      "description": "Stores embeddings and forecast loss for each iteration to enable metalearning updates."
    },
    "iteration-check": {
      "label": "Iteration multiple of U?",
      "description": "Periodic check to determine when to perform metalearning updates to improve the system."
    },
    "update": {
      "label": "Update: Introspector G & Series Embedder",
      "description": "Meta-learning update using forecast performance to improve both components."
    }
  },

  "epsilon_status": "Epsilon-Greedy Status",
  "phase": "Phase",
  "epsilon": "Epsilon (Œµ)",
  "random_value": "Random Value",
  "strategy": "Strategy",
  "warmup": "üî• WARMUP",
  "active": "üéØ ACTIVE",
  "explore": "üé≤ EXPLORE",
  "exploit": "üß† EXPLOIT",
  "progress": "Progress",
  "step": "Step {{current}} of {{total}}",
  "complete": "Pipeline complete! The system continues iterating to improve performance through metalearning.",
  "current_step": "Current Step",
  "node_details": "Node Details",
  "legend": "Legend",
  "legend_items": {
    "process": "Process",
    "data": "Data Store",
    "decision_exploit": "Decision (Exploit)",
    "decision_explore": "Decision (Explore)"
  },


  "connections": {
    "true": "True",
    "false": "False",
    "meta_update": "Meta-learning update using forecast performance",
    "embeddings": "Embeddings",
    "loss": "Forecast Loss"
  },
  "epsilon_expl": {
    "warmup": "Warmup phase: Always exploring randomly",
    "explore": "{{value}} < {{epsilon}} ‚Üí Explore randomly",
    "exploit": "{{value}} ‚â• {{epsilon}} ‚Üí Exploit best variables"
  }
}
