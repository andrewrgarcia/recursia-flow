{
  "title": "Flujo de Selecci√≥n de Variables en Series Temporales con IA",
  "subtitle": "Sistema agn√≥stico basado en meta-aprendizaje para elegir variables de pron√≥stico",
  "author": "Andrew Garcia, PhD 2025",
  "controls": {
    "play": "Reproducir",
    "pause": "Pausa",
    "reset": "Reiniciar",
    "lang": {
      "en": "EN",
      "es": "ES"
    }
  },

  "what_is_meta_title": "¬øQu√© es el Meta-aprendizaje?",
  "what_is_meta_text": "Meta-aprendizaje significa 'aprender a aprender'. En este sistema, la experiencia proviene del rendimiento de los modelos de pron√≥stico, no solo de los datos en bruto. Despu√©s de cada prueba, el sistema observa si los pron√≥sticos mejoraron o empeoraron y vincula ese resultado con descriptores de las variables seleccionadas ‚Äî ya sea sus metadatos (instituci√≥n, fecha de inicio, clasificaci√≥n) o su √≠ndice posicional en la base de datos. Al iterar este ciclo, el sistema aprende reglas para una mejor selecci√≥n con el tiempo. Como aprende a partir de los resultados de otros procesos de aprendizaje, literalmente est√° 'aprendiendo a aprender'.",

  "explain_like_5_title": "Explica la Introspecci√≥n Recursiva como si tuviera 5 a√±os üë∂",
  "explain_like_5_text": "Imagina que eliges jugadores para un equipo. Al inicio pruebas jugadores al azar. Ves c√≥mo juega el equipo ‚öΩ. La pr√≥xima vez recuerdas qui√©n lo hizo bien üß† y lo eliges otra vez. A veces pruebas alguien nuevo üé≤, por si acaso. Con el tiempo, tu equipo mejora porque aprendes a escoger la mejor mezcla. Eso es lo que hace la Introspecci√≥n Recursiva: aprende a elegir las mejores variables para pronosticar la econom√≠a.",


  "orientation_note": "Smartphone detectado ‚Äî usa la orientaci√≥n horizontal y minimiza el encabezado con el bot√≥n.",

  "nodes": {
    "database": {
      "label": "Base de Datos de Series Temporales",
      "description": "Repositorio hist√≥rico completo de series temporales con todas las variables disponibles y sus patrones temporales."
    },
    "warmup-note": {
      "warmupLabel": "Durante calentamiento: siempre aleatorio",
      "activeLabel": "Despu√©s de calentamiento: epsilon-greedy",
      "warmupDesc": "Durante la fase de calentamiento, el sistema siempre explora aleatoriamente para recopilar datos iniciales.",
      "activeDesc": "Despu√©s del calentamiento, el sistema usa la estrategia epsilon-greedy para equilibrar exploraci√≥n y explotaci√≥n."
    },
    "decision": {
      "label": "Punto de decisi√≥n",
      "description": "Decisi√≥n basada en el umbral de epsilon"
    },
    "introspector": {
      "label": "Introspector G",
      "description": "Red neuronal que aprende a seleccionar las variables m√°s informativas basadas en el rendimiento hist√≥rico."
    },
    "random-picker": {
      "label": "Selector Aleatorio de Variables",
      "description": "Selecciona variables al azar para explorar combinaciones potencialmente √∫tiles."
    },
    "selected-vars": {
      "label": "Variables Seleccionadas",
      "description": "El conjunto elegido de variables provenientes de la estrategia de explotaci√≥n o exploraci√≥n."
    },
    "embedder": {
      "label": "Incrustador de Series (con Metadatos)",
      "description": "Transforma las series temporales seleccionadas en representaciones vectoriales densas. Obtiene: incrustaciones de variables seleccionadas."
    },
    "forecasting": {
      "label": "Modelo de Pron√≥stico",
      "description": "Regresores Random Forest, redes neuronales personalizadas, VARs, lo que quieras. Salida: p√©rdida de pron√≥stico."
    },
    "history": {
      "label": "(Incrustaciones, P√©rdida) ‚Üí Registro Hist√≥rico",
      "description": "Almacena incrustaciones y p√©rdida de pron√≥stico en cada iteraci√≥n para habilitar actualizaciones de meta-aprendizaje."
    },
    "iteration-check": {
      "label": "¬øIteraci√≥n es m√∫ltiplo de U?",
      "description": "Revisi√≥n peri√≥dica para determinar cu√°ndo realizar actualizaciones de meta-aprendizaje."
    },
    "update": {
      "label": "Actualizar: Introspector G & Incrustador de Series",
      "description": "Actualizaci√≥n de meta-aprendizaje usando el rendimiento del pron√≥stico para mejorar ambos componentes."
    }
  },


  "epsilon_status": "Estado Epsilon-Greedy",
  "phase": "Fase",
  "epsilon": "Epsilon (Œµ)",
  "random_value": "Valor Aleatorio",
  "strategy": "Estrategia",
  "warmup": "üî• CALENTAMIENTO",
  "active": "üéØ ACTIVO",
  "explore": "üé≤ EXPLORAR",
  "exploit": "üß† EXPLOTAR",
  "progress": "Progreso",
  "step": "Paso {{current}} de {{total}}",
  "complete": "¬°Pipeline completo! El sistema sigue iterando para mejorar el rendimiento mediante meta-aprendizaje.",
  "current_step": "Paso Actual",
  "node_details": "Detalles del Nodo",
  "legend": "Leyenda",
  "legend_items": {
    "process": "Proceso",
    "data": "Almac√©n de Datos",
    "decision_exploit": "Decisi√≥n (Explotar)",
    "decision_explore": "Decisi√≥n (Explorar)"
  },

  "connections": {
    "true": "Verdadero",
    "false": "Falso",
    "meta_update": "Actualizaci√≥n de meta-aprendizaje usando el rendimiento del pron√≥stico",
    "embeddings": "Incrustaciones",
    "loss": "P√©rdida de Pron√≥stico"  
  },
  "epsilon_expl": {
    "warmup": "Fase de calentamiento: Siempre explorando aleatoriamente",
    "explore": "{{value}} < {{epsilon}} ‚Üí Explorar aleatoriamente",
    "exploit": "{{value}} ‚â• {{epsilon}} ‚Üí Explotar mejores variables"
  }
}
